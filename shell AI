{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMae6Vwmjy02s171evsoemp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunvkofficial/ARUNVK/blob/main/shell%20AI\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4Hn17-lBrxN",
        "outputId": "409be5cd-bb1d-439d-f9f6-c06d9514507d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llamaapi\n",
            "  Downloading llamaapi-0.1.36-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.5 in /usr/local/lib/python3.10/dist-packages (from llamaapi) (3.9.5)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from llamaapi) (1.6.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from llamaapi) (2.31.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.27.1->llamaapi) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.27.1->llamaapi) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.27.1->llamaapi) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.27.1->llamaapi) (2024.7.4)\n",
            "Downloading llamaapi-0.1.36-py3-none-any.whl (4.0 kB)\n",
            "Installing collected packages: llamaapi\n",
            "Successfully installed llamaapi-0.1.36\n"
          ]
        }
      ],
      "source": [
        "pip install llamaapi\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from llamaapi import LlamaAPI\n",
        "\n",
        "# Initialize the Llama API with your token\n",
        "llama = LlamaAPI(\"LL-Qig6k4VbqcY1vfjf14pJ4FkhsK5G13C8vhsWKsiekTBw10GA3aFW4YsQmzvrPN7d\")\n",
        "\n",
        "def prompt_to_command(prompt):\n",
        "    # Define the API request payload with specific instruction to output only the command\n",
        "    api_request_json = {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "            {\"role\": \"assistant\", \"content\": \"Give only the command.\"}\n",
        "        ],\n",
        "        \"stream\": False\n",
        "    }\n",
        "\n",
        "    # Execute the API request\n",
        "    try:\n",
        "        response = llama.run(api_request_json)\n",
        "        response_data = response.json()\n",
        "\n",
        "        # Check for the existence of the 'choices' key in the response\n",
        "        if \"choices\" in response_data and len(response_data[\"choices\"]) > 0:\n",
        "            # Extract the command from the response\n",
        "            command = response_data[\"choices\"][0][\"message\"][\"content\"]\n",
        "            return command.strip()\n",
        "        else:\n",
        "            print(\"No command generated.\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "# Ask the user for a prompt\n",
        "user_prompt = input(\"Enter your prompt: \")\n",
        "\n",
        "# Get the command from the prompt\n",
        "command = prompt_to_command(user_prompt)\n",
        "\n",
        "# Display and execute the command\n",
        "if command:\n",
        "    print(f\"Generated Command: {command}\")\n",
        "    try:\n",
        "        # Execute the command (Note: Use with caution)\n",
        "        print(f\"Executing Command: {command}\")\n",
        "        # Use os.system to execute the command\n",
        "        import os\n",
        "        os.system(command)\n",
        "    except Exception as exec_error:\n",
        "        print(f\"Execution Error: {exec_error}\")\n",
        "else:\n",
        "    print(\"No command to execute.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf6werefB672",
        "outputId": "85850cff-abaf-4d2d-ea4b-1a7927417570"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your prompt: how to connect ssh to this ip 192.168.45.3\n",
            "Generated Command: ssh user@192.168.45.3\n",
            "Executing Command: ssh user@192.168.45.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from llamaapi import LlamaAPI\n",
        "\n",
        "# Initialize the Llama API with your token\n",
        "llama = LlamaAPI(\"LL-Qig6k4VbqcY1vfjf14pJ4FkhsK5G13C8vhsWKsiekTBw10GA3aFW4YsQmzvrPN7d\")\n",
        "\n",
        "def prompt_to_command(prompt):\n",
        "    \"\"\"Converts a natural language prompt to a command using Llama API.\"\"\"\n",
        "    api_request_json = {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "            {\"role\": \"assistant\", \"content\": \"Give only the command.\"}\n",
        "        ],\n",
        "        \"stream\": False\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = llama.run(api_request_json)\n",
        "        response_data = response.json()\n",
        "        if \"choices\" in response_data and len(response_data[\"choices\"]) > 0:\n",
        "            command = response_data[\"choices\"][0][\"message\"][\"content\"]\n",
        "            return command.strip()\n",
        "        else:\n",
        "            print(\"No command generated.\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "def rag_agent(command):\n",
        "    \"\"\"Enhances command execution with rule-based modifications.\"\"\"\n",
        "    # Example rules for command modifications\n",
        "    if \"ping\" in command:\n",
        "        if not any(char.isdigit() for char in command):\n",
        "            return \"ping 8.8.8.8\"  # Default to a safe IP if none provided\n",
        "    if \"ls\" in command and \"-l\" not in command:\n",
        "        return command + \" -l\"  # Add detailed listing option to 'ls'\n",
        "    # Add more rules as needed\n",
        "    return command\n",
        "\n",
        "def execute_command(command):\n",
        "    \"\"\"Executes the given command and provides detailed feedback.\"\"\"\n",
        "    try:\n",
        "        print(f\"Executing Command: {command}\")\n",
        "        os.system(command)\n",
        "    except Exception as exec_error:\n",
        "        print(f\"Execution Error: {exec_error}\")\n",
        "\n",
        "def main():\n",
        "    # Ask the user for a prompt\n",
        "    user_prompt = input(\"Enter your prompt: \")\n",
        "\n",
        "    # Get the command from the prompt\n",
        "    command = prompt_to_command(user_prompt)\n",
        "\n",
        "    # Display and execute the command\n",
        "    if command:\n",
        "        print(f\"Generated Command: {command}\")\n",
        "        command = rag_agent(command)  # Enhance command with RAG agent\n",
        "        execute_command(command)\n",
        "    else:\n",
        "        print(\"No command to execute.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hl42eQBRFQNk",
        "outputId": "1717b5a9-f72b-46e4-d99a-537f15415fc9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your prompt: i want to crack a password using hydra tool\n",
            "Generated Command: hydra -l <username> -P <wordlist> <protocol>://<host>:<port>\n",
            "Executing Command: hydra -l <username> -P <wordlist> <protocol>://<host>:<port>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "import json\n",
        "import subprocess\n",
        "import re\n",
        "from llamaapi import LlamaAPI\n",
        "\n",
        "# Initialize the Llama API with your token\n",
        "llama = LlamaAPI(\"LL-Qig6k4VbqcY1vfjf14pJ4FkhsK5G13C8vhsWKsiekTBw10GA3aFW4YsQmzvrPN7d\")\n",
        "\n",
        "def prompt_to_command(prompt):\n",
        "    \"\"\"Converts a natural language prompt to a command using Llama API.\"\"\"\n",
        "    api_request_json = {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "            {\"role\": \"assistant\", \"content\": \"Give only the command.\"}\n",
        "        ],\n",
        "        \"stream\": False\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = llama.run(api_request_json)\n",
        "        response_data = response.json()\n",
        "        if \"choices\" in response_data and len(response_data[\"choices\"]) > 0:\n",
        "            command = response_data[\"choices\"][0][\"message\"][\"content\"]\n",
        "            return command.strip()\n",
        "        else:\n",
        "            print(\"No command generated.\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "def rag_agent(command):\n",
        "    \"\"\"Enhances command execution with rule-based modifications and automation.\"\"\"\n",
        "\n",
        "    if not command:\n",
        "        return None\n",
        "\n",
        "    # Safety checks and common command modifications\n",
        "    if re.search(r\"rm\\s+-rf\\s+/\", command):\n",
        "        print(\"Unsafe command detected. Aborting execution.\")\n",
        "        return None\n",
        "\n",
        "    if \"ping\" in command and not re.search(r\"\\d+\\.\\d+\\.\\d+\\.\\d+\", command):\n",
        "        print(\"No IP address found in the command, defaulting to 8.8.8.8.\")\n",
        "        return \"ping 8.8.8.8\"\n",
        "\n",
        "    if \"ls\" in command and \"-l\" not in command:\n",
        "        print(\"Adding detailed listing option to 'ls' command.\")\n",
        "        command += \" -l\"\n",
        "\n",
        "    if command.startswith(\"mkdir\"):\n",
        "        folder_name = command.split()[-1]\n",
        "        if os.path.exists(folder_name):\n",
        "            print(f\"Directory {folder_name} already exists.\")\n",
        "            return None\n",
        "        else:\n",
        "            print(f\"Creating directory: {folder_name}\")\n",
        "            command = f\"mkdir -p {folder_name}\"\n",
        "\n",
        "    if command.startswith(\"rm\"):\n",
        "        print(\"Adding -i option to 'rm' command to confirm each removal.\")\n",
        "        command = command.replace(\"rm\", \"rm -i\", 1)\n",
        "\n",
        "    # Automation tasks\n",
        "    if \"update system\" in command:\n",
        "        print(\"Automating system update.\")\n",
        "        return \"sudo apt-get update && sudo apt-get upgrade -y\"\n",
        "\n",
        "    if \"backup\" in command:\n",
        "        parts = command.split()\n",
        "        if len(parts) == 3:\n",
        "            source, destination = parts[1], parts[2]\n",
        "            print(f\"Automating backup from {source} to {destination}.\")\n",
        "            return f\"rsync -avh --progress {source} {destination}\"\n",
        "        else:\n",
        "            print(\"Incorrect backup command format. Use 'backup source destination'.\")\n",
        "            return None\n",
        "\n",
        "    # Additional rules for specific commands and automations can be added here\n",
        "\n",
        "    return command\n",
        "\n",
        "def execute_command(command):\n",
        "    \"\"\"Executes the given command and provides detailed feedback.\"\"\"\n",
        "    if command:\n",
        "        try:\n",
        "            print(f\"Executing Command: {command}\")\n",
        "            result = subprocess.run(command, shell=True, check=True, text=True, capture_output=True)\n",
        "            print(result.stdout)\n",
        "        except subprocess.CalledProcessError as exec_error:\n",
        "            print(f\"Execution Error: {exec_error}\")\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred: {e}\")\n",
        "    else:\n",
        "        print(\"No command to execute.\")\n",
        "\n",
        "def main():\n",
        "    user_prompt = input(\"Enter your prompt: \")\n",
        "    command = prompt_to_command(user_prompt)\n",
        "    if command:\n",
        "        print(f\"Generated Command: {command}\")\n",
        "        command = rag_agent(command)\n",
        "        if command:\n",
        "            execute_command(command)\n",
        "        else:\n",
        "            print(\"No command to execute after RAG agent processing.\")\n",
        "    else:\n",
        "        print(\"No command to execute.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "EfjTz-JTGVPv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}